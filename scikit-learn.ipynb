{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46fc446f",
   "metadata": {},
   "source": [
    "# Scikit-Learn (sklearn)\n",
    "\n",
    "Below are useful functions of the Scikit-Learn library\n",
    "\n",
    "0. An end-to-end Scikit-Learn workflow\n",
    "1. Getting the data ready\n",
    "2. Choose the right estimator/algorithm for our problems\n",
    "3. Fit the model/algorithm and use it to make predictions on the data\n",
    "4. Evaluating a model\n",
    "5. Improve a model\n",
    "6. Save and load a trained model\n",
    "7. Putting it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64dea358",
   "metadata": {},
   "source": [
    "## 0. An end-to-end Scikit-Learn workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ca1632cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0     63    1   3       145   233    1        0      150      0      2.3   \n",
       "1     37    1   2       130   250    0        1      187      0      3.5   \n",
       "2     41    0   1       130   204    0        0      172      0      1.4   \n",
       "3     56    1   1       120   236    0        1      178      0      0.8   \n",
       "4     57    0   0       120   354    0        1      163      1      0.6   \n",
       "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
       "298   57    0   0       140   241    0        1      123      1      0.2   \n",
       "299   45    1   3       110   264    0        1      132      0      1.2   \n",
       "300   68    1   0       144   193    1        1      141      0      3.4   \n",
       "301   57    1   0       130   131    0        1      115      1      1.2   \n",
       "302   57    0   1       130   236    0        0      174      0      0.0   \n",
       "\n",
       "     slope  ca  thal  target  \n",
       "0        0   0     1       1  \n",
       "1        0   0     2       1  \n",
       "2        2   0     2       1  \n",
       "3        2   0     2       1  \n",
       "4        2   0     2       1  \n",
       "..     ...  ..   ...     ...  \n",
       "298      1   0     3       0  \n",
       "299      1   0     3       0  \n",
       "300      1   2     3       0  \n",
       "301      1   1     3       0  \n",
       "302      1   1     2       0  \n",
       "\n",
       "[303 rows x 14 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Get the data ready\n",
    "import pandas as pd\n",
    "heart_disease = pd.read_csv(\"heart-disease.csv\")\n",
    "heart_disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a72f1f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create X (features matrix)\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "\n",
    "#Create y (Labels)\n",
    "y = heart_disease[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6cddb8ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Choose the right model and hyperparameters\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# We will keep the default hyperparameters\n",
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3c3d193e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the model to the training data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8bb8bd34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "839f725c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hameed/Desktop/WebDevelopment/sample_project/env/lib/python3.10/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[0. 2. 3. 4.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 3. Fit the model/algorithm and use it to make predictions on the data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m y_label \u001b[38;5;241m=\u001b[39m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/WebDevelopment/sample_project/env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:823\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    803\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;124;03m    Predict class for X.\u001b[39;00m\n\u001b[1;32m    805\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;124;03m        The predicted classes.\u001b[39;00m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 823\u001b[0m     proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    825\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    826\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39margmax(proba, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/WebDevelopment/sample_project/env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:865\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    863\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    864\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[0;32m--> 865\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_X_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[1;32m    868\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n",
      "File \u001b[0;32m~/Desktop/WebDevelopment/sample_project/env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:599\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;124;03mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001b[39;00m\n\u001b[1;32m    598\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 599\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[1;32m    601\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/WebDevelopment/sample_project/env/lib/python3.10/site-packages/sklearn/base.py:604\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    602\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 604\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[1;32m    606\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m~/Desktop/WebDevelopment/sample_project/env/lib/python3.10/site-packages/sklearn/utils/validation.py:940\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    938\u001b[0m     \u001b[38;5;66;03m# If input is 1D raise error\u001b[39;00m\n\u001b[1;32m    939\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 940\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    941\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    942\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    943\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    944\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m    945\u001b[0m         )\n\u001b[1;32m    947\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(array\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkind\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    948\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    949\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    950\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    951\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[0. 2. 3. 4.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "# 3. Fit the model/algorithm and use it to make predictions on the data\n",
    "y_label = clf.predict(np.array([0, 2, 3, 4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16240487",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = clf.predict(X_test)\n",
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a7c933",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0b654d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Evaluate the model on the training data and test data\n",
    "clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6ad724",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df195fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da6b144",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8e059c",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddbacb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Improve a model\n",
    "#Try different amount of n_estimators\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "for i in range(10, 100, 10):\n",
    "    print(f\"Trying model with {i} estimators..\")\n",
    "    clf = RandomForestClassifier(n_estimators=i).fit(X_train, y_train)\n",
    "    print(f\"Model accuracy on test set: {clf.score(X_test, y_test) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7355cbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Save a model and load it\n",
    "import pickle\n",
    "\n",
    "pickle.dump(clf, open(\"random_forest_model_1.pk1\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e82cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open(\"random_forest_model_1.pk1\", \"rb\"))\n",
    "loaded_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6173cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plot\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048c9bdd",
   "metadata": {},
   "source": [
    "# 1. Getting our data ready to be used with machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25996ae",
   "metadata": {},
   "source": [
    "# Three main things we have to do:\n",
    "    1. Split the data into features and labels (usually 'X' & 'Y')\n",
    "    2. Filling ( also called imputing) or disregarding missing value\n",
    "    3. Converting non-numerical values to numerical values (feature encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba84b168",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0333a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad81c345",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = heart_disease[\"target\"]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69db933",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into trainig and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y, \n",
    "                                                    test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5a0fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d488ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576c1282",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(heart_disease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cb3ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape[0] * 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a69a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 Make sure data is all numerical\n",
    "#Example using the car values\n",
    "car_sales = pd.read_csv(\"car-sales.csv\")\n",
    "car_sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8136a57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales['Price'] = car_sales['Price'].replace('[\\$\\,\\.]', '', regex=True).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cd4ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales[\"Price\"]= car_sales[\"Price\"]/100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bf0690",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291cf480",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c700e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into X/y\n",
    "X= car_sales.drop(\"Price\", axis=1)\n",
    "y= car_sales[\"Price\"]\n",
    "\n",
    "#Split into training and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y, \n",
    "                                                    test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22ea85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build machine learning model \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33799873",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turn the categories into numbers to deal with issue ^\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "categorical_features = [\"Make\", \"Colour\", \"Doors\"]\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([(\"one_hot\",\n",
    "                                  one_hot,\n",
    "                                  categorical_features)],\n",
    "                                  remainder=\"passthrough\")\n",
    "#^ used the one_hot encoder to change all categorical features into numbers\n",
    "# so machine can process, \"passthrough\" is make sure the other features are ignored\n",
    "# essentially turning categories into numbers\n",
    "transformed_X = transformer.fit_transform(X)\n",
    "transformed_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2c3e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8828383e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(transformed_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc21652",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(car_sales[[\"Make\", \"Colour\", \"Doors\"]])\n",
    "dummies\n",
    "\n",
    "#Essentially all we did here is below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb3c929",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's refit the model \n",
    "np.random.seed(42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(transformed_X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4338929a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2419c7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784fd5de",
   "metadata": {},
   "source": [
    "# 1.2 What if there were missing values?\n",
    "\n",
    "1. Fill them with some value (imputation)\n",
    "2. Remove the samples with missing data altogether."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f5bba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import car sales missing data\n",
    "car_sales_missing = pd.read_csv(\"car-sales-extended-missing-data.csv\")\n",
    "car_sales_missing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0f5cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44db3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create X & y\n",
    "X = car_sales_missing.drop(\"Price\", axis=1)\n",
    "y = car_sales_missing[\"Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af890798",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turn the categories into numbers to deal with issue ^\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "categorical_features = [\"Make\", \"Colour\", \"Doors\"]\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([(\"one_hot\",\n",
    "                                  one_hot,\n",
    "                                  categorical_features)],\n",
    "                                  remainder=\"passthrough\")\n",
    "#^ used the one_hot encoder to change all categorical features into numbers\n",
    "# so machine can process, \"passthrough\" is make sure the other features are ignored\n",
    "# essentially turning categories into numbers\n",
    "transformed_X = transformer.fit_transform(X)\n",
    "transformed_X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb51466",
   "metadata": {},
   "source": [
    "# Option 1: Fill missing data with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d25425",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill the \"make\" column\n",
    "car_sales_missing[\"Make\"].fillna(\"missing\", inplace=True)\n",
    "\n",
    "#Fill the \"Colour\" column\n",
    "car_sales_missing[\"Colour\"].fillna(\"missing\", inplace=True)\n",
    "\n",
    "#Fill the \"Odometer (KM)\" column\n",
    "car_sales_missing[\"Odometer (KM)\"].fillna(car_sales_missing[\"Odometer (KM)\"].mean(), inplace=True)\n",
    "\n",
    "#Fill the \"Doors\" columns\n",
    "car_sales_missing[\"Doors\"].fillna(4, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c286015",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the dataframe again\n",
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3215f906",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove rows with missing Price Values \n",
    "car_sales_missing.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cf8b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bd6b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(car_sales_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd7c5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = car_sales_missing.drop(\"Price\", axis=1)\n",
    "y = car_sales_missing[\"Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985765d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turn the categories into numbers to deal with issue ^\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "categorical_features = [\"Make\", \"Colour\", \"Doors\"]\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([(\"one_hot\",\n",
    "                                  one_hot,\n",
    "                                  categorical_features)],\n",
    "                                  remainder=\"passthrough\")\n",
    "#^ used the one_hot encoder to change all categorical features into numbers\n",
    "# so machine can process, \"passthrough\" is make sure the other features are ignored\n",
    "# essentially turning categories into numbers\n",
    "transformed_X = transformer.fit_transform(car_sales_missing)\n",
    "transformed_X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbffb24",
   "metadata": {},
   "source": [
    "## Option 2: Fill missing values in scikit learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001dfc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing = pd.read_csv(\"car-sales-extended-missing-data.csv\")\n",
    "car_sales_missing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6f66c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361788f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing.dropna(subset=[\"Price\"], inplace=True)\n",
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e96017",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into X & y\n",
    "X = car_sales_missing.drop(\"Price\", axis=1)\n",
    "y = car_sales_missing[\"Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706dac59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "#Fill categorical values with 'missing' & numerical values with mean\n",
    "cat_imputer = SimpleImputer(strategy=\"constant\", fill_value=\"missing\")\n",
    "door_imputer = SimpleImputer(strategy=\"constant\", fill_value=4)\n",
    "num_imputer = SimpleImputer(strategy=\"mean\")\n",
    "\n",
    "#Define columns\n",
    "cat_features= [\"Make\", \"Colour\"]\n",
    "door_features = [\"Doors\"]\n",
    "num_features = [\"Odometer (KM)\"]\n",
    "\n",
    "# Create an imputer (something that fills missing data)\n",
    "imputer = ColumnTransformer([\n",
    "    (\"categ_imputer\", cat_imputer, cat_features),\n",
    "    (\"door_imputer\", door_imputer, door_features),\n",
    "    (\"num_imputer\", num_imputer, num_features)\n",
    "    \n",
    "])\n",
    "\n",
    "#Transform the data\n",
    "filled_X = imputer.fit_transform(X)\n",
    "filled_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751232b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_filled = pd.DataFrame(filled_X,\n",
    "                               columns=[\"Make\", \"Colours\", \"Doors\", \"Odometer (KM)\"])\n",
    "car_sales_filled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e53c818",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_filled.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81251102",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "categorical_features = [\"Make\", \"Colours\", \"Doors\"]\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([(\"one_hot\",\n",
    "                                  one_hot,\n",
    "                                  categorical_features)],\n",
    "                                  remainder=\"passthrough\")\n",
    "#^ used the one_hot encoder to change all categorical features into numbers\n",
    "# so machine can process, \"passthrough\" is make sure the other features are ignored\n",
    "# essentially turning categories into numbers\n",
    "transformed_X = transformer.fit_transform(car_sales_filled)\n",
    "transformed_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1023dcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we've got outr data as numbers and filled (no missing values)\n",
    "#Let's fit a model\n",
    "np.random.seed(42)\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(transformed_X,\n",
    "                                                   y,\n",
    "                                                   test_size=0.2)\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293ad627",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(car_sales_filled)\n",
    "#Model not doign good because the dataset is small"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ebf6ee",
   "metadata": {},
   "source": [
    "# 2. Choosing the right estimator/algorithm for your algorithm\n",
    "\n",
    "Things to note: \n",
    "  * Sklearn refers to machine learning models, algorithms as estimators.\n",
    "  * Classification problem - predicting a category (heart disease or not)\n",
    "    * Sometimes you'll see 'clf' (short for classifier) used as a classification estimator\n",
    "   * Regression problem - predicting a number (selling price of a car)\n",
    "   \n",
    "   \n",
    "For what algorithm to use => https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f85dec",
   "metadata": {},
   "source": [
    "## 2.1 Picking a machine learning model for a regression problem\n",
    "\n",
    "Using the California housing dataset from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf25a0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get California Housing dataset\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing(as_frame=True)\n",
    "housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab816001",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the ensemble algorithm module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd73662a",
   "metadata": {},
   "source": [
    "## 2.2 Choosing an estimator for a classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c83d3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at the map\n",
    "heart_disease = pd.read_csv(\"heart-disease.csv\")\n",
    "heart_disease.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276c0238",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(heart_disease)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc145aba",
   "metadata": {},
   "source": [
    "### Looking at the map, lets try the LinearSVC algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5945cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the LinearSVC estimator class\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "#Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "#Make the data\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "#Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Instantiate LinearSVC\n",
    "clf = LinearSVC()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#Evaluate the LinearSVC\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb882b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716470ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets try ensemble algo\n",
    "#Import the RandomForestClassifier estimator class\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "#Make the data\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "#Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Instantiate Random Forest Classifier\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#Evaluate the Random Forest Classifier\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fc3b5b",
   "metadata": {},
   "source": [
    "In summary:\n",
    "    \n",
    "    1. If you have structured data (in a table), use ensemble methods\n",
    "    2. If you have unstructured data(e.g. images), use deep learning or transfer learning\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d823356",
   "metadata": {},
   "source": [
    "# 3. Fit the model/algorithm on our data and use it to make predictions\n",
    "\n",
    "### 3.1 Fitting the model to the data \n",
    "\n",
    "### Different names for: \n",
    "    * X = features, feature variables, data\n",
    "    * y = labels, targets, target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8e8bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the RandomForestClassifier estimator class\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "#Make the data\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "#Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Instantiate Random Forest Classifier\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "#Fit the model to the data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#Evaluate the Random Forest Classifier (use the patterns the model has learned)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91112dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf6cbf6",
   "metadata": {},
   "source": [
    "  ### 3.2 Make predictions using a machine learning model\n",
    "  \n",
    "  2 ways to make predictions:\n",
    "  \n",
    "      1. predict()\n",
    "      2. predict_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f8e75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a trained model to make predictions\n",
    "clf.predict(np.array([1, 7, 8, 3, 4])) #will not work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e3d643",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e1d57d",
   "metadata": {},
   "outputs": [],
   "source": [
    " clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8357f98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b235ef33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare prediction to truth labels to evaluate the model\n",
    "y_preds = clf.predict(X_test)\n",
    "np.mean(y_preds == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce36c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed5e506",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83dfea02",
   "metadata": {},
   "source": [
    "### Make predictions with predict_proba()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c9ff18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict proba() returns probabilities of a classification label\n",
    "clf.predict_proba(X_test[:5])\n",
    "#Showing the probability of the target being true or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b4c714",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's predict() on the same data\n",
    "clf.predict(X_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88218249",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d694b190",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae17cb0",
   "metadata": {},
   "source": [
    "`predict()` can also be used for regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dce0f5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48aca77d",
   "metadata": {},
   "source": [
    "## 4.Evaluating a machine learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b23873d",
   "metadata": {},
   "source": [
    "### Three ways to evaluate Scikit-Learn models/estimators:\n",
    "        1. Estimator's built-in `score()` method\n",
    "        2. The `scoring` parameter\n",
    "        3. Problem-specific metric functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fd2cca",
   "metadata": {},
   "source": [
    "### 4.1 Evaluating a model with the `score` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4dba3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "#Make the data\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "#Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Instantiate Random Forest Classifier\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "#Fit the model to the data\n",
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7913daa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The highest value for the .score() method is 1.0, the lowest is 0.0\n",
    "clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beca7ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64d0945",
   "metadata": {},
   "source": [
    "Lets do the same for the regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2946f6d2",
   "metadata": {},
   "source": [
    "### 4.2 Evaluating a model using th `scoring` parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7aac31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "#Make the data\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "#Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Instantiate Random Forest Classifier\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "#Fit the model to the data\n",
    "clf.fit(X_train, y_train);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81c38a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf13b4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model is trained on 5 different versions of training data, and evaluated on 5 different\n",
    "#versions of the test data.\n",
    "cross_val_score(clf, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248a7360",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(clf, X, y, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6122f4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "#Single training and test split score\n",
    "clf_single_score = clf.score(X_test, y_test)\n",
    "\n",
    "#Take the mean of the 5-fold cross-validation score\n",
    "clf_cross_val_score = np.mean(cross_val_score(clf, X, y, cv=5))\n",
    "\n",
    "#Compare the two\n",
    "clf_single_score, clf_cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2ab1dc",
   "metadata": {},
   "source": [
    "### 4.2.1 Classification model evaluation metrics\n",
    "\n",
    "    1. Accuracy\n",
    "    2. Area under the ROC curve\n",
    "    3. Confusion matrix\n",
    "    4. Classification report\n",
    "    \n",
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bce2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X= heart_disease.drop(\"target\", axis=1)\n",
    "y= heart_disease[\"target\"]\n",
    "\n",
    "clf= RandomForestClassifier()\n",
    "cross_val_score = cross_val_score(clf, X, y, cv=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0896f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(cross_val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4adcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Heart Disease Classifier Cross-Validated Accuracy: {np.mean(cross_val_score) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90355956",
   "metadata": {},
   "source": [
    "** Area under the receiver operatign characteristic curve (AUC/ROC)\n",
    "\n",
    "* Area under the curve (AUC)\n",
    "* ROC Curve\n",
    "\n",
    "ROC curves are a comparison of a models true positive rate (tpr) versus a models false positive rate(fpr)\n",
    "\n",
    "*True positive = model predicts 1 when the truth is 1\n",
    "* False positive = model predicts 1 when the truth is 0\n",
    "* True negative = model predicts 0 when the truth is 0\n",
    "* False negative = model predicts 0 when truth is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1741bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create X _test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58738589",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "#Fit the classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#Make predictions with probabilities\n",
    "y_probs = clf.predict_proba(X_test)\n",
    "\n",
    "y_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c9832f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probs_positive = y_probs[:, 1]\n",
    "y_probs_positive[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd55774",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate fpr, tpr, and thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_probs_positive)\n",
    "\n",
    "#Check the false positive rates\n",
    "fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0214c9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function for plotting ROC curves\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_roc_curve(fpr, tpr):\n",
    "    \"\"\"\n",
    "    Plots a ROC Curve given the false positive rate (fpr) and the true\n",
    "    positive rate(tpr) of a model.\n",
    "    \"\"\"\n",
    "    #plot roc curve\n",
    "    plt.plot(fpr, tpr, color=\"orange\", label=\"ROC\")\n",
    "    #Plot line with no predictive power (baseline)\n",
    "    plt.plot([0,1], [0, 1], color=\"darkblue\", linestyle=\"--\", label=\"Guessing\")\n",
    "    \n",
    "    #Customize the plot\n",
    "    plt.xlabel(\"False positive rate (fpr)\")\n",
    "    plt.ylabel(\"True positive rate (tpr)\")\n",
    "    plt.title(\"Receiver Operating Characteristics (ROC) Curve\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "plot_roc_curve(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b02c5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(y_test, y_probs_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c39338d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot perfect ROC curve and AUC score\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_test)\n",
    "plot_roc_curve(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7ae353",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perfect AUC score\n",
    "roc_auc_score(y_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2dab4a6",
   "metadata": {},
   "source": [
    "** Confusion Matrix **\n",
    "\n",
    "A confusion matrix is a quick way to compare the labels a model predicts anf the actuals\n",
    "labels it was supposed to predict.\n",
    "\n",
    "In essence, giving you an idea of where the model is getting ocnfused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959f6a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_preds = clf.predict(X_test)\n",
    "\n",
    "confusion_matrix(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a590e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize confusion matrix with pd.crosstab()\n",
    "\n",
    "pd.crosstab(y_test,\n",
    "           y_preds,\n",
    "           rownames=[\"Actual Labels\"],\n",
    "           colnames=[\"Predicted Labels\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50dc3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cf48f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!conda install --yes --prefix {sys.prefix} seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7415d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make our confusion matrix more visual with Seaborn's heatmap()\n",
    "import seaborn as sns\n",
    "\n",
    "#Set the font scale\n",
    "sns.set(font_scale=1.5)\n",
    "\n",
    "#Create a confusion matrix\n",
    "conf_mat = confusion_matrix(y_test, y_preds)\n",
    "\n",
    "#Plot it using Seaborn\n",
    "sns.heatmap(conf_mat);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0086db73",
   "metadata": {},
   "source": [
    "### Creating a confusion matrix using Scikit-Learn\n",
    "\n",
    "To use the methods of creating a confusion matrix with Scikit-Learn you will need sklearn version 1.0+\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dbcf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf5f061",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(estimator=clf, X=X, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b19447b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(y_true=y_test,\n",
    "                                       y_pred=y_preds);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e8f279",
   "metadata": {},
   "source": [
    "### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee21738",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0a6fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where precision and recall become valuable\n",
    "disease_true = np.zeros(10000)\n",
    "disease_true[0] = 1 #only one positive case\n",
    "\n",
    "disease_preds = np.zeros(10000) #model predicts every case as 0\n",
    "\n",
    "pd.DataFrame(classification_report(disease_true,\n",
    "                                  disease_preds,\n",
    "                                  output_dict=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d1440e",
   "metadata": {},
   "source": [
    "To summarize classification metrics:\n",
    "    \n",
    "    *Accuracy is a good measure to start with if all classes are balanced(e.g. same amount of sample)\n",
    "    *Precision and recall become more important when classes are imbalanced\n",
    "    *If false positive predictions are worse than false negatives, aim for higher precision.\n",
    "    * If false negative predictions are worse than false positives, aim for higher recall.\n",
    "    * F1-score is a combination of precision and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4964b302",
   "metadata": {},
   "source": [
    "### 4.2.2 Regression model evaluation metrics\n",
    "\n",
    "1. R^2 (coefficient of determination)\n",
    "2. Mean absolute error (MAE)\n",
    "3. Mean squared error (MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8836171f",
   "metadata": {},
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "np.random.seed(42) \n",
    "\n",
    "X = housing_df.drop(\"target\", axis=1)\n",
    "y=housing_df[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_test.mean()\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "y_test_mean = np.full(len(y_test), y_test.mean())\n",
    "\n",
    "r2_score(y_true=y_test,\n",
    "         y_pred=y_test_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa96997b",
   "metadata": {},
   "source": [
    "*** Mean Absolute Error (MAE) ***\n",
    "MAE is the average of the absolute differences between predictions and actual values\n",
    "\n",
    "It givrs you an idea of how wrong your models predictions are.\n",
    "\n",
    "#MAE\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "y_preds = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_preds)\n",
    "mae\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f621db",
   "metadata": {},
   "source": [
    "Mean Square Error\n",
    "\n",
    "MSE is the mean of the square of the errors between actual and predicted values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5daf8382",
   "metadata": {},
   "source": [
    "## 4.2.3 Finally using the `scoring` parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9634e201",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "clf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717e21f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "#Cross-validation accuracy\n",
    "cv_acc = cross_val_score(clf, X, y, cv=5, scoring=None) # if scoring=None, estimators default scoring evaluation metric is used (accuracy for evaluation models)\n",
    "cv_acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f310e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross-validated accuracy\n",
    "print(f\"Heart Disease Classifier Cross-Validated Accuracy: {np.mean(cv_acc) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b9ff00",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "cv_acc = cross_val_score(clf, X, y, cv=5, scoring=\"accuracy\")\n",
    "cv_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531cb9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross-validated accuracy\n",
    "print(f\"The cross-validated accuracy is : {np.mean(cv_acc) * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69a539e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Precision\n",
    "np.random.seed(42)\n",
    "cv_precision = cross_val_score(clf, X, y, cv=5, scoring=\"precision\")\n",
    "cv_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b19593e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross-validated precision\n",
    "print(f\"The cross-validated precision is : {np.mean(cv_precision)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe8d2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recall\n",
    "cv_recall = cross_val_score(clf, X, y, cv=5, scoring=\"recall\")\n",
    "cv_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549a9454",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross-validated recall\n",
    "print(f\"The cross-validated recall is : {np.mean(cv_recall)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6ebd8a",
   "metadata": {},
   "source": [
    "Let's see the `scoring` parameter being used for a regression problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b571342",
   "metadata": {},
   "source": [
    "## 4.3 Using different evaluation metrics as Scikit_Learn functions\n",
    "\n",
    "The 3rd way to evaluate sckit-learn machine learning models/estimators is to use the `sklearn.metrics`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17efd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(42)\n",
    "#Create X & y\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "#Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "#Create a model\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "#Fit Model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#Make predictions\n",
    "y_preds = clf.predict(X_test)\n",
    "\n",
    "#Evaluate model using evaluation functions\n",
    "print(\"Classifier metrics on the test set\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_preds)*100:.2f}%\")\n",
    "print(f\"Precision: {precision_score(y_test, y_preds)}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_preds)}\")\n",
    "print(f\"F1: {f1_score(y_test, y_preds)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bb3627",
   "metadata": {},
   "source": [
    "## 5. Improving a model\n",
    "\n",
    "First predictions = baseline predictions\n",
    "First model = baseline model.\n",
    "\n",
    "From a data perspective:\n",
    "* Could we collect more data? (generally, the more data, the better)\n",
    "* Could we improve our data? \n",
    "    \n",
    "From a model perspective:\n",
    "* Is there a better model we could use?\n",
    "* Could we improve the current model?\n",
    "   \n",
    "Hyperparameters vs Parameters \n",
    "\n",
    "* Parameters = model find these patterns in data\n",
    "* Hyperparameters = settings on a model you can adjust to (potentially) improve its ability to find patterns\n",
    "\n",
    "Three ways to adjust hyperparameters: \n",
    "\n",
    "1. By Hand\n",
    "2. Randomly with RandomSearchCV\n",
    "3. Exhaustively with GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec4d491",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5956e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce55964f",
   "metadata": {},
   "source": [
    "### 5.1 Tuning hyperparameters by hand\n",
    "\n",
    "Let's make 3 sets, training, validation, and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002f3bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e87f710",
   "metadata": {},
   "source": [
    "We're going to try and adjust: \n",
    "\n",
    "* `max_depth`\n",
    "* `max_features`\n",
    "* `min_samples_leaf`\n",
    "* `min_samples_split`\n",
    "* `n_estimators`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fcffed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_preds(y_true, y_preds):\n",
    "    \"\"\"\n",
    "    Performs evaluation comparisoon on y_true labels vs. y_pred labels.\n",
    "    \n",
    "    \"\"\"\n",
    "    accuracy = accuracy_score(y_true, y_preds)\n",
    "    precision = precision_score(y_true, y_preds)\n",
    "    recall = recall_score(y_true, y_preds)\n",
    "    f1 = f1_score(y_true, y_preds)\n",
    "    metric_dict = {\"accuracy\": round(accuracy, 2),\n",
    "                  \"precision\": round(precision, 2),\n",
    "                  \"recall\": round(recall, 2),\n",
    "                  \"f1\": round(f1, 2)}\n",
    "    print(f\"Acc: {accuracy * 100:.2f}%\")\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"F1 score: {f1:.2f}\")\n",
    "    \n",
    "    return metric_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "44e120fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 82.22%\n",
      "Precision: 0.81\n",
      "Recall: 0.88\n",
      "F1 score: 0.85\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.82, 'precision': 0.81, 'recall': 0.88, 'f1': 0.85}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "#Shuffle the data\n",
    "heart_disease_shuffled = heart_disease.sample(frac=1)\n",
    "\n",
    "#Split into X & y\n",
    "X= heart_disease_shuffled.drop(\"target\", axis=1)\n",
    "y = heart_disease_shuffled[\"target\"]\n",
    "\n",
    "#Split the data into train, validation, & test sets\n",
    "train_split = round(0.7 * len(heart_disease_shuffled)) # 70% of data\n",
    "valid_split = round(train_split + 0.15 * len(heart_disease_shuffled)) # 15% of data\n",
    "X_train, y_train = X[:train_split], y[:train_split]\n",
    "X_valid = X[train_split:valid_split]\n",
    "y_valid = y[train_split:valid_split]\n",
    "X_test, y_test = X[valid_split:], y[valid_split:]\n",
    "\n",
    "len(X_train), len(X_valid), len(X_test)\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#Make baseline predictions\n",
    "y_preds = clf.predict(X_valid)\n",
    "\n",
    "#Evaluate the classifier on validation set\n",
    "baseline_metrics = evaluate_preds(y_valid, y_preds)\n",
    "baseline_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dec296a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 82.22%\n",
      "Precision: 0.84\n",
      "Recall: 0.84\n",
      "F1 score: 0.84\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "#Create a second classifier with different hyperparameters\n",
    "clf_2 = RandomForestClassifier(n_estimators=100)\n",
    "clf_2.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions with different hyperparameters\n",
    "y_preds_2 = clf_2.predict(X_valid)\n",
    "\n",
    "#Evaluate the 2nd classifier\n",
    "clf_2_metrics = evaluate_preds(y_valid, y_preds_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b992da81",
   "metadata": {},
   "source": [
    "## 5.2 Hyperparameter tuning with RandomizedSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6b4ed692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1200; total time=   1.4s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1200; total time=   1.2s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1200; total time=   1.2s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1200; total time=   1.2s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1200; total time=   1.4s\n",
      "[CV] END max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.3s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.3s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   0.6s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   0.6s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   0.6s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   0.6s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   0.6s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=1000; total time=   1.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=1000; total time=   1.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=1000; total time=   1.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=1000; total time=   1.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=1000; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hameed/Desktop/WebDevelopment/sample_project/env/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "20 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/hameed/Desktop/WebDevelopment/sample_project/env/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/hameed/Desktop/WebDevelopment/sample_project/env/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/hameed/Desktop/WebDevelopment/sample_project/env/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/hameed/Desktop/WebDevelopment/sample_project/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/hameed/Desktop/WebDevelopment/sample_project/env/lib/python3.10/site-packages/sklearn/model_selection/_search.py:976: UserWarning: One or more of the test scores are non-finite: [0.82244898        nan 0.80620748        nan 0.80595238        nan\n",
      " 0.81428571 0.83886054        nan 0.81428571]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(n_jobs=1),\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [None, 5, 10, 20, 30],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 4, 6],\n",
       "                                        &#x27;n_estimators&#x27;: [10, 100, 200, 500,\n",
       "                                                         1000, 1200]},\n",
       "                   verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(n_jobs=1),\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [None, 5, 10, 20, 30],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 4, 6],\n",
       "                                        &#x27;n_estimators&#x27;: [10, 100, 200, 500,\n",
       "                                                         1000, 1200]},\n",
       "                   verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_jobs=1)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_jobs=1)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(n_jobs=1),\n",
       "                   param_distributions={'max_depth': [None, 5, 10, 20, 30],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 4, 6],\n",
       "                                        'n_estimators': [10, 100, 200, 500,\n",
       "                                                         1000, 1200]},\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "grid = {\"n_estimators\": [10, 100, 200, 500, 1000, 1200],\n",
    "       \"max_depth\": [None, 5, 10, 20, 30],\n",
    "       \"max_features\": [\"auto\", \"sqrt\"],\n",
    "       \"min_samples_split\": [2, 4, 6],\n",
    "       \"min_samples_leaf\": [1, 2, 4]}\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "#Split into X & y\n",
    "X = heart_disease_shuffled.drop(\"target\", axis=1)\n",
    "y = heart_disease_shuffled[\"target\"]\n",
    "\n",
    "#Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "#Instantiate RandomForestClassifier\n",
    "clf= RandomForestClassifier(n_jobs=1)\n",
    "\n",
    "#Setup RandomizedSearchCV\n",
    "rs_clf = RandomizedSearchCV(estimator=clf, \n",
    "                           param_distributions=grid,\n",
    "                           n_iter=10, #numbers of models to try\n",
    "                           cv=5, \n",
    "                           verbose=2)\n",
    "\n",
    "# Fit the RandomizedSearchCV version of clf\n",
    "rs_clf.fit(X_train, y_train)\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c5b8e487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 200,\n",
       " 'min_samples_split': 6,\n",
       " 'min_samples_leaf': 2,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': None}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b9916372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 81.97%\n",
      "Precision: 0.77\n",
      "Recall: 0.86\n",
      "F1 score: 0.81\n"
     ]
    }
   ],
   "source": [
    "# Make predictions with the best hyperparameters\n",
    "rs_y_preds = rs_clf.predict(X_test)\n",
    "\n",
    "#Evaluate the predictions\n",
    "rs_metrics = evaluate_preds(y_test, rs_y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f1ccfe",
   "metadata": {},
   "source": [
    "### 5.3 Hyperparameter tuning with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d0891f17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': [10, 100, 200, 500, 1000, 1200],\n",
       " 'max_depth': [None, 5, 10, 20, 30],\n",
       " 'max_features': ['auto', 'sqrt'],\n",
       " 'min_samples_split': [2, 4, 6],\n",
       " 'min_samples_leaf': [1, 2, 4]}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "10d1d303",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_2 = {'n_estimators': [100, 200, 500],\n",
    "         'max_depth': [None],\n",
    "         'max_features': ['auto', 'sqrt'],\n",
    "         'min_samples_split': [6],\n",
    "         'min_samples_leaf': [1, 2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "352e82ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=200; total time=   0.3s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=200; total time=   0.3s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=200; total time=   0.3s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=500; total time=   0.6s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=500; total time=   0.6s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=500; total time=   1.2s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=500; total time=   0.6s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=500; total time=   0.6s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.3s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   0.6s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   0.6s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   0.6s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   0.6s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hameed/Desktop/WebDevelopment/sample_project/env/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "30 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/hameed/Desktop/WebDevelopment/sample_project/env/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/hameed/Desktop/WebDevelopment/sample_project/env/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/hameed/Desktop/WebDevelopment/sample_project/env/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/hameed/Desktop/WebDevelopment/sample_project/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/hameed/Desktop/WebDevelopment/sample_project/env/lib/python3.10/site-packages/sklearn/model_selection/_search.py:976: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      " 0.82270408 0.81811224 0.82244898 0.82253401 0.82236395 0.81011905]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(n_jobs=1),\n",
       "             param_grid={&#x27;max_depth&#x27;: [None], &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2], &#x27;min_samples_split&#x27;: [6],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200, 500]},\n",
       "             verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(n_jobs=1),\n",
       "             param_grid={&#x27;max_depth&#x27;: [None], &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2], &#x27;min_samples_split&#x27;: [6],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200, 500]},\n",
       "             verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_jobs=1)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_jobs=1)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(n_jobs=1),\n",
       "             param_grid={'max_depth': [None], 'max_features': ['auto', 'sqrt'],\n",
       "                         'min_samples_leaf': [1, 2], 'min_samples_split': [6],\n",
       "                         'n_estimators': [100, 200, 500]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "#Split into X & y\n",
    "X = heart_disease_shuffled.drop(\"target\", axis=1)\n",
    "y = heart_disease_shuffled[\"target\"]\n",
    "\n",
    "#Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "#Instantiate RandomForestClassifier\n",
    "clf= RandomForestClassifier(n_jobs=1)\n",
    "\n",
    "#Setup GridSearchCV\n",
    "gs_clf = GridSearchCV(estimator=clf, \n",
    "                           param_grid=grid_2,\n",
    "                           cv=5, \n",
    "                           verbose=2)\n",
    "\n",
    "# Fit the RandomizedSearchCV version of clf\n",
    "gs_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4265d560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': None,\n",
       " 'max_features': 'sqrt',\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 6,\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b997cb3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 81.97%\n",
      "Precision: 0.77\n",
      "Recall: 0.86\n",
      "F1 score: 0.81\n"
     ]
    }
   ],
   "source": [
    "gs_y_preds = gs_clf.predict(X_test)\n",
    "\n",
    "#evaluate the predictions\n",
    "gs_metrics = evaluate_preds(y_test, gs_y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006e1ea5",
   "metadata": {},
   "source": [
    "Let's compare our models metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "72af10c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzoAAALECAYAAADAXkVpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABENUlEQVR4nO3debhVBb3/8c9hnlGZVUZBo8BUuBbOQ+JUNl0zNXEAE0FJwYnKuStaCmZe5wErpzT11s1EchaHFHECTGMQ1GMEJDgk4/n94c9zO8FBDnLOxsXr9Tz7ib322mt9N7I7vFlrr11WUVFREQAAgAKpV+oBAAAA1jehAwAAFI7QAQAACkfoAAAAhSN0AACAwhE6AABA4QgdAACgcBqUeoC1sXLlyrz11ltp2bJlysrKSj0OAABQIhUVFXn33Xez+eabp1696o/bfCZC56233krnzp1LPQYAALCBmDt3brbccstqH/9MhE7Lli2TfPRiWrVqVeJpAACAUlm8eHE6d+5c2QjV+UyEzsenq7Vq1UroAAAAn/iRFhcjAAAACkfoAAAAhSN0AACAwvlMfEYHoMhWrFiRZcuWlXoMCqhhw4apX79+qccAKAmhA1AiFRUVefvtt/POO++UehQKbJNNNknHjh19Dx2w0RE6ACXyceS0b98+zZo18xdR1quKiop88MEHmTdvXpKkU6dOJZ4IoG4JHYASWLFiRWXktGnTptTjUFBNmzZNksybNy/t27d3GhuwUXExAoAS+PgzOc2aNSvxJBTdx3/GfA4M2NgIHYAScroatc2fMWBjJXQAAIDCEToA1Mgee+yRk046qWT7P+qoo/KNb3xjg5kHgA2TixEAbGC6nfGHOtvX7AsPrLN91Za77rorDRs2LPUYAGxghA4An2mbbbZZqUcAYAPk1DUAamz58uU54YQTsskmm6RNmzb58Y9/nIqKiiTJr3/96/Tv3z8tW7ZMx44dc9hhh1V+l0uS/OMf/8jhhx+edu3apWnTpunVq1duvPHGysfffPPNHHLIIdl0003Tpk2bfP3rX8/s2bOrneXfT13r1q1bLrjgghxzzDFp2bJlunTpkmuuuabKc2q6DwA+e4QOADV20003pUGDBnn66adz2WWXZdy4cbnuuuuSJEuXLs3555+fF154Iffcc09mzZqVo446qvK5Z555ZqZNm5Y//vGPmT59eq688sq0bds2SfLBBx9kzz33TIsWLfLoo4/m8ccfT4sWLbLffvtl6dKlaz3fJZdckv79+2fKlCkZNmxYjj/++LzyyivrdR8AbNicugZAjXXu3Dnjxo1LWVlZttlmm7z00ksZN25cjj322BxzzDGV6/Xo0SOXXXZZdtxxx7z33ntp0aJF5syZk+233z79+/dP8tERmI/ddtttqVevXq677rrKyyLfeOON2WSTTfLwww9n4MCBazXfAQcckGHDhiVJTj/99IwbNy4PP/xwPve5z623fQCwYXNEB4Aa+/KXv1zl+1kGDBiQ1157LStWrMiUKVPy9a9/PV27dk3Lli2zxx57JEnmzJmTJDn++ONz2223Zbvttstpp52WJ554onI7kydPzl//+te0bNkyLVq0SIsWLbLZZpvlww8/zIwZM9Z6vm233bby12VlZenYsWPl6XPrax8AbNgc0QFgvfnwww8zcODADBw4ML/+9a/Trl27zJkzJ/vuu2/laWH7779/Xn/99fzhD3/In/70p+y9994ZPnx4Lr744qxcuTL9+vXLzTffvMq227Vrt9Zz/PtV2MrKyrJy5cokWW/7AGDDJnQAqLGnnnpqlfu9evXKK6+8kvnz5+fCCy9M586dkyTPPvvsKs9v165djjrqqBx11FHZddddc+qpp+biiy/ODjvskNtvvz3t27dPq1atamX2utgHAKXn1DUAamzu3LkZOXJk/vKXv+TWW2/NL37xi/zgBz9Ily5d0qhRo/ziF7/IzJkz87vf/S7nn39+leeeddZZ+Z//+Z/89a9/zdSpU/O///u/6d27d5Lk8MMPT9u2bfP1r389jz32WGbNmpVHHnkkP/jBD/LGG2+sl9nrYh8AlJ7QAaDGBg0alH/+85/ZcccdM3z48Jx44on5/ve/n3bt2mX8+PG544478vnPfz4XXnhhLr744irPbdSoUUaPHp1tt902u+22W+rXr5/bbrstSdKsWbM8+uij6dKlS771rW+ld+/eOeaYY/LPf/5zvR19qYt9AFB6ZRUff/HBBmzx4sVp3bp1Fi1a5IcQUAgffvhhZs2ale7du6dJkyalHocC82cNKJq1bQNHdAAAgMIROgAAQOEIHQAAoHCEDgAAUDhCBwAAKBxfGAoAdejFN96p1e1vu+Umtbp9gM8KR3QAAIDCEToAAEDhCB0AAKBwhA4AAFA4LkYAsKE5p3Ud7mvRetvU7Nmz071790yZMiXbbbddkmTSpEkZOnRoXnnllRx44IG555571tv+AGBNHNEBoNaMHDky2223XWbNmpXx48evcd0XXnghhx56aDp37pymTZumd+/e+fnPf143gwJQOI7oAFBrZsyYkaFDh2bLLbf8xHUnT56cdu3a5de//nU6d+6cJ554It///vdTv379nHDCCXUwLQBF4ogOADWycuXKXHTRRenZs2caN26cLl265L/+67+qrDN79uyUlZVlwYIFOeaYY1JWVvaJR3SOOeaYXHbZZdl9993To0ePfO9738vRRx+du+66qxZfDQBF5YgOADUyevToXHvttRk3blx22WWXlJeX55VXXqmyTufOnVNeXp5tttkm5513Xg455JC0bl3zzx4tWrQom2222foaHYCNiNABYK29++67+fnPf57LL788Rx55ZJJkq622yi677JLZs2dXrle/fv107NgxZWVlad26dTp27FjjfT355JP5zW9+kz/84Q/ra3wANiJOXQNgrU2fPj1LlizJ3nvvXav7mTp1ar7+9a/nrLPOyj777FOr+wKgmIQOAGutadOmtb6PadOmZa+99sqxxx6bH//4x7W+PwCKyalrAKy1Xr16pWnTpnnggQcyZMiQ9b79qVOnZq+99sqRRx65ygUO2DD0valvrW7/N2OW1+r2k6T3K9NrfR9A6QkdANZakyZNcvrpp+e0005Lo0aNsvPOO+fvf/97pk6d+qlPZ5s6dWr23HPPDBw4MCNHjszbb7+d5KPP+7Rr1259jA/ARkToAGxozllU6gnW6Mwzz0yDBg1y1lln5a233kqnTp0ydOjQT73dO+64I3//+99z88035+abb65c3rVr1yoXOgCAtVFWUVFRUeohPsnixYvTunXrLFq0KK1atSr1OACf2ocffphZs2ale/fuadKkSanHoQ69+MY7tbr9bbfcpMr99f1nzalrQKmtbRu4GAEAAFA4QgeAOjF06NC0aNFitbf1ceobAPwrn9EBoE6cd955OeWUU1b7mNOSAVjfhA4AdaJ9+/Zp3759qccANgDdzvhDrW5/9oUH1ur2+Wxw6hoAAFA4QgcAACgcoQMAABSO0AEAAApH6AAAAIXjqmtAcZzTupa3v6h2t///1fY3z/+rl458qc72ta6OOuqovPPOO7nnnntKPcoG4YudN824a3+dvfar5qpSb02pen95RfLO35PLD07em/vpB+je5dNvA2pbQX4e8Ok4ogMAABSO0AHgU1m6dGmpRyiMZcuWlXoEgMIQOgDUyB577JETTjghI0eOTNu2bbPPPvskScaOHZu+ffumefPm6dy5c4YNG5b33nuv8nnjx4/PJptskgkTJqR3795p0aJF9ttvv5SXl1eus2LFiowcOTKbbLJJ2rRpk9NOOy0VFRVV9r9kyZKMGDEi7du3T5MmTbLLLrvkmWeeqXz84YcfTllZWSZMmJDtt98+TZs2zV577ZV58+blj3/8Y3r37p1WrVrl0EMPzQcffFDt63z99dfzta99LZtuummaN2+eL3zhC7n33nsrH582bVoOOOCAtGjRIh06dMgRRxyR+fPnVz5+3333ZZdddql8LV/96lczY8aMysffnDsnX+y8aSb8/u4MPvir+Y+eHfOHu36TJLn7tl/nm3sPSP+tOmTvfp/LBT8+tcps7/xjQU4a8r18qdfm+dqu/fLw/fcGgKqEDgA1dtNNN6VBgwaZNGlSrr766iRJvXr1ctlll+Xll1/OTTfdlAcffDCnnXZaled98MEHufjii/OrX/0qjz76aObMmZNTTjml8vFLLrkkN9xwQ66//vo8/vjjWbhwYe6+++4q2zjttNPy29/+NjfddFOee+659OzZM/vuu28WLlxYZb1zzjknl19+eZ544onMnTs33/nOd3LppZfmlltuyR/+8IdMnDgxv/jFL6p9jcOHD8+SJUvy6KOP5qWXXspFF12UFi1aJEnKy8uz++67Z7vttsuzzz6b++67L3/729/yne98p/L577//fkaOHJlnnnkmDzzwQOrVq5dvfvObWblyZZX9XDrmnBx6zHG5+8Gns9Pue+U3v7w+Y358av7zsCNz58RJ+fn1t6RLtx5VnnPVuIuy71e/kTvufzy77LVPRo84Lov+8Y9P+s8GsFFxMQIAaqxnz5756U9/WmXZSSedVPnr7t275/zzz8/xxx+fK664onL5smXLctVVV2WrrbZKkpxwwgk577zzKh+/9NJLM3r06Hz7299Oklx11VWZMGFC5ePvv/9+rrzyyowfPz77779/kuTaa6/NxIkTc/311+fUU//vyMdPfvKT7LzzzkmSwYMHZ/To0ZkxY0Z69PgoGv7zP/8zDz30UE4//fTVvsY5c+bk29/+dvr2/ejiEB8/L0muvPLK7LDDDrngggsql91www3p3LlzXn311Wy99daVr+Fj119/fdq3b58Zr76SXp/7fOXy7w0+Pl/Z/2uV96+57JIM+v7wHD54aOWyPtvtUGVbBx18WPb/xn8mSU48/czceuM1efn5ydl5z6+s9rUAbIwc0QGgxvr377/Ksoceeij77LNPtthii7Rs2TKDBg3KggUL8v7771eu06xZs8rISZJOnTpl3rx5SZJFixalvLw8AwYMqHy8QYMGVfY1Y8aMLFu2rDJgkqRhw4bZcccdM3369CrzbLvttpW/7tChQ5o1a1YlVjp06FC579UZMWJEZSydffbZefHFFysfmzx5ch566KG0aNGi8va5z32ucsaP//ewww5Ljx490qpVq3Tv3j1J8vZbb1TZz+e33a7y1wvm/z1//1t5dtxl92rnSpKte3+h8tfNmjVP8xYtsnDB/DU8A2DjI3QAqLHmzZtXuf/666/ngAMOSJ8+ffLb3/42kydPzn//938nqfoB+4YNG1Z5XllZ2SqfwVmTj9ctKytbZfm/L/vXfZWVla123/9+Gtm/GjJkSGbOnJkjjjgiL730Uvr37195qtvKlSvzta99Lc8//3yV22uvvZbddtstSfK1r30tCxYsyLXXXpunn346Tz/9dJJk2dKqFxxo2uz/fi+bNGmyVr8PDRrU7LUAbIyEDgCf2rPPPpvly5fnkksuyZe//OVsvfXWeeutt2q0jdatW6dTp0556qmnKpctX748kydPrrzfs2fPNGrUKI8//njlsmXLluXZZ59N7969P/0L+TedO3fO0KFDc9ddd2XUqFG59tprkyQ77LBDpk6dmm7duqVnz55Vbs2bN8+CBQsyffr0/PjHP87ee++d3r175x9r8Rma5i1aZvPOXfLnxx9Z768FYGMjdAD41LbaaqssX748v/jFLzJz5sz86le/ylVXXVXj7fzgBz/IhRdemLvvvjuvvPJKhg0blnfeeafy8ebNm+f444/Pqaeemvvuuy/Tpk3Lsccemw8++CCDBw9ej6/oo88cTZgwIbNmzcpzzz2XBx98sDKmhg8fnoULF+bQQw/Nn//858ycOTP3339/jjnmmKxYsSKbbrpp2rRpk2uuuSZ//etf8+CDD2bkyJFrtd/jTz4jv7zmv3PzDVfn9VkzMv2lF3LLjdes19cGsDFwMQKADcxLR75U6hFqbLvttsvYsWNz0UUXZfTo0dltt90yZsyYDBo0qEbbGTVqVMrLy3PUUUelXr16OeaYY/LNb34zixb937eQX3jhhVm5cmWOOOKIvPvuu+nfv38mTJiQTTfddL2+phUrVmT48OF544030qpVq+y3334ZN25ckmTzzTfPpEmTcvrpp2fffffNkiVL0rVr1+y3336pV69eysrKctttt2XEiBHp06dPttlmm1x22WXZY489PnG/Bx18aJYs+TC/vu7KjP3Jmdl00zb5yoEHrdfXBrAxKKuoycnRJbJ48eK0bt06ixYtSqtWrUo9DrChOqd1LW9/0Sevs5Y+/PDDzJo1K927d1/rz2VQDC++8U6tbn/berOq3P9weUVmvfn3dJ80Kk3em/upt9+3e5dPvY01+c2Y5bW6/STp/cr0T16JWtXtjD/U6vZnNzmsVre/Pn8eUHNr2wZOXQMAAApH6AAAAIXjMzp1pLYP0Sa1f5j2s366glMVAAA2Ho7oAAAAhSN0AACAwhE6AABA4QgdAACgcIQOAABQOK66BtSZ2v+CuFrdPJ/S7Nmz071790yZMiXbbbfdatd5+OGHs+eee+Yf//hHNtlkkzqd79M46qij8s477+See+4p9ShAHeh7U99a3b4r0a4fQgdgAzP9c73rbF91+cOuc+fOKS8vT9u2betsnwBsvJy6BkCtW7p0aerXr5+OHTumQYPP1r+xLV26tNQjALAO1il0rrjiinTv3j1NmjRJv3798thjj61x/Ztvvjlf/OIX06xZs3Tq1ClHH310FixYsE4DA1Ba7777bg4//PA0b948nTp1yrhx47LHHnvkpJNOqlynW7du+clPfpKjjjoqrVu3zrHHHpvZs2enrKwszz//fOV69957b7beeus0bdo0e+65Z2bPnv2J+z/nnHPSpUuXNG7cOJtvvnlGjBhR+djSpUtz2mmnZYsttkjz5s3zpS99KQ8//HDl4wsWLMihhx6aLbfcMs2aNUvfvn1z6623Vtn+HnvskRNOOCEjR45M27Zts88++yRJpk6dmgMPPDCtWrVKy5Yts+uuu2bGjBlVnnvxxRenU6dOadOmTYYPH55ly5at/W8sAOtVjUPn9ttvz0knnZQf/ehHmTJlSnbdddfsv//+mTNnzmrXf/zxxzNo0KAMHjw4U6dOzR133JFnnnkmQ4YM+dTDA1D3Ro4cmUmTJuV3v/tdJk6cmMceeyzPPffcKuv97Gc/S58+fTJ58uSceeaZqzw+d+7cfOtb38oBBxyQ559/PkOGDMkZZ5yxxn3feeedGTduXK6++uq89tprueeee9K37/+dK3/00Udn0qRJue222/Liiy/m4IMPzn777ZfXXnstSfLhhx+mX79++d///d+8/PLL+f73v58jjjgiTz/9dJX93HTTTWnQoEEmTZqUq6++Om+++WZ22223NGnSJA8++GAmT56cY445JsuX/9959A899FBmzJiRhx56KDfddFPGjx+f8ePH1+S3FoD1qMbnD4wdOzaDBw+uDJVLL700EyZMyJVXXpkxY8assv5TTz2Vbt26Vf6LW/fu3XPcccflpz/96accHYC69u677+amm27KLbfckr333jtJcuONN2bzzTdfZd299torp5xySuX9fz9ac+WVV6ZHjx4ZN25cysrKss022+Sll17KRRddVO3+58yZk44dO+YrX/lKGjZsmC5dumTHHXdMksyYMSO33npr3njjjcp5TjnllNx333258cYbc8EFF2SLLbaoMtOJJ56Y++67L3fccUe+9KUvVS7v2bNnlZ9TP/zhD9O6devcdtttadiwYZJk6623rjLbpptumssvvzz169fP5z73uRx44IF54IEHcuyxx67x9xSA2lGjIzpLly7N5MmTM3DgwCrLBw4cmCeeeGK1z9lpp53yxhtv5N57701FRUX+9re/5c4778yBBx5Y7X6WLFmSxYsXV7kBUHozZ87MsmXLKuMiSVq3bp1tttlmlXX79++/xm1Nnz49X/7yl1NWVla5bMCAAWt8zsEHH5x//vOf6dGjR4499tjcfffdlUdVnnvuuVRUVGTrrbdOixYtKm+PPPJI5SlmK1asyH/9139l2223TZs2bdKiRYvcf//9q5yV8O+zP//889l1110rI2d1vvCFL6R+/fqV9zt16pR58+at8fUAUHtqdERn/vz5WbFiRTp06FBleYcOHfL222+v9jk77bRTbr755hxyyCH58MMPs3z58hx00EH5xS9+Ue1+xowZk3PPPbcmowFQByoqKpKkSpz86/J/1bx587XaVk107tw5f/nLXzJx4sT86U9/yrBhw/Kzn/0sjzzySFauXJn69etn8uTJVYIjSVq0aJEkueSSSzJu3Lhceuml6du3b5o3b56TTjpplQsO/PvsTZs2/cTZ/j2CysrKsnLlyhq/RgDWj3W6GMHqfsD9+7KPTZs2LSNGjMhZZ52VyZMn57777susWbMydOjQarc/evToLFq0qPI2d+7cdRkTgPVsq622SsOGDfPnP/+5ctnixYsrPwNTE5///Ofz1FNPVVn27/dXp2nTpjnooINy2WWX5eGHH86TTz6Zl156Kdtvv31WrFiRefPmpWfPnlVuHTt2TJI89thj+frXv57vfe97+eIXv5gePXqs1ezbbrttHnvsMRcXAPgMqVHotG3bNvXr11/l6M28efNWOcrzsTFjxmTnnXfOqaeemm233Tb77rtvrrjiitxwww0pLy9f7XMaN26cVq1aVbkBUHotW7bMkUcemVNPPTUPPfRQpk6dmmOOOSb16tWr9h+8qjN06NDMmDEjI0eOzF/+8pfccsstn/jh/fHjx+f666/Pyy+/nJkzZ+ZXv/pVmjZtmq5du2brrbfO4YcfnkGDBuWuu+7KrFmz8swzz+Siiy7Kvffem+Sjz95MnDgxTzzxRKZPn57jjjuu2jMS/tUJJ5yQxYsX57vf/W6effbZvPbaa/nVr36Vv/zlLzV6zQDUnRqFTqNGjdKvX79MnDixyvKJEydmp512Wu1zPvjgg9SrV3U3H59SsC6nLQBQWmPHjs2AAQPy1a9+NV/5yley8847p3fv3mnSpEmNttOlS5f89re/ze9///t88YtfzFVXXZULLrhgjc/ZZJNNcu2112bnnXfOtttumwceeCC///3v06ZNmyQfXRhh0KBBGTVqVLbZZpscdNBBefrpp9O5c+ckyZlnnpkddtgh++67b/bYY4907Ngx3/jGNz5x1jZt2uTBBx/Me++9l9133z39+vXLtddeu8bP7ABQWmUVNayN22+/PUcccUSuuuqqDBgwINdcc02uvfbaTJ06NV27ds3o0aPz5ptv5pe//GWSj/717dhjj81ll12WfffdN+Xl5TnppJNSr169VS7nWZ3FixendevWWbRo0Wf26E63M/5Q6/uY3eSwWt1+3+5danX7vxmz/JNX+hTq8hvgWb3afh/U9nsg5yxab5v68MMPM2vWrMrvJPsse//997PFFlvkkksuyeDBg0s9zgbvxTfeqdXtb1tvVpX7Hy6vyKw3/57uk0alyXuf/lTwz/rPgsTPgw3BZ/3nwWf9ffBZfw+sbRvU+PLShxxySBYsWJDzzjsv5eXl6dOnT+6999507do1SVJeXl7l6jVHHXVU3n333Vx++eUZNWpUNtlkk+y1115rvHwoABuuKVOm5JVXXsmOO+6YRYsW5bzzzkuSfP3rXy/xZADwf2ocOkkybNiwDBs2bLWPre786hNPPDEnnnjiuuwKgA3QxRdfnL/85S+VpzQ/9thjadu2banHAoBK6xQ6AGy8tt9++0yePLnUYwDAGq3T5aUBAAA2ZEIHAAAoHKEDUEIrV64s9QgU3MqKJKlIVq4o9SgAdcpndABKoFGjRqlXr17eeuuttGvXLo0aNarxF27y2VSxfGmtbv/Deh99a0RFRbJ0ZfL3RR+m3j8XptE/59XqfgE2NEIHoATq1auX7t27p7y8PG+99Vapx6EOzfvHP2t1+43K/v5/d1YuT7O/T0mXV25MvYra/34agA2J0AEokUaNGqVLly5Zvnx5VqxwWtHGYshdD9fq9h9ofMpHv6ioSP1l76bB0sUpS42+GxygEIQOQAmVlZWlYcOGadiwYalHoY68+W7tRm2TZXNrdfsAnxUuRgAAABSO0AEAAApH6AAAAIUjdAAAgMIROgAAQOG46hrAWup7U99a38dvxtTud530fmV6rW4fADYUjugAAACFI3QAAIDCEToAAEDhCB0AAKBwhA4AAFA4QgcAACgcoQMAABSO0AEAAApH6AAAAIUjdAAAgMIROgAAQOEIHQAAoHCEDgAAUDhCBwAAKByhAwAAFI7QAQAACkfoAAAAhSN0AACAwhE6AABA4QgdAACgcIQOAABQOEIHAAAoHKEDAAAUjtABAAAKR+gAAACFI3QAAIDCEToAAEDhCB0AAKBwhA4AAFA4QgcAACgcoQMAABSO0AEAAApH6AAAAIUjdAAAgMIROgAAQOEIHQAAoHCEDgAAUDhCBwAAKByhAwAAFI7QAQAACkfoAAAAhSN0AACAwhE6AABA4QgdAACgcIQOAABQOEIHAAAoHKEDAAAUjtABAAAKR+gAAACFI3QAAIDCEToAAEDhCB0AAKBwhA4AAFA4QgcAACgcoQMAABSO0AEAAApH6AAAAIUjdAAAgMIROgAAQOEIHQAAoHCEDgAAUDhCBwAAKByhAwAAFI7QAQAACkfoAAAAhSN0AACAwhE6AABA4QgdAACgcIQOAABQOEIHAAAoHKEDAAAUjtABAAAKR+gAAACFI3QAAIDCEToAAEDhCB0AAKBwhA4AAFA4QgcAACgcoQMAABSO0AEAAApH6AAAAIUjdAAAgMIROgAAQOEIHQAAoHCEDgAAUDhCBwAAKByhAwAAFI7QAQAACkfoAAAAhSN0AACAwhE6AABA4QgdAACgcIQOAABQOEIHAAAoHKEDAAAUjtABAAAKR+gAAACFI3QAAIDCEToAAEDhCB0AAKBwhA4AAFA4QgcAACgcoQMAABSO0AEAAApH6AAAAIUjdAAAgMIROgAAQOEIHQAAoHDWKXSuuOKKdO/ePU2aNEm/fv3y2GOPrXH9JUuW5Ec/+lG6du2axo0bZ6uttsoNN9ywTgMDAAB8kgY1fcLtt9+ek046KVdccUV23nnnXH311dl///0zbdq0dOnSZbXP+c53vpO//e1vuf7669OzZ8/Mmzcvy5cv/9TDAwAArE6NQ2fs2LEZPHhwhgwZkiS59NJLM2HChFx55ZUZM2bMKuvfd999eeSRRzJz5sxsttlmSZJu3bp9uqkBAADWoEanri1dujSTJ0/OwIEDqywfOHBgnnjiidU+53e/+1369++fn/70p9liiy2y9dZb55RTTsk///nPavezZMmSLF68uMoNAABgbdXoiM78+fOzYsWKdOjQocryDh065O23317tc2bOnJnHH388TZo0yd1335358+dn2LBhWbhwYbWf0xkzZkzOPffcmowGAABQaZ0uRlBWVlblfkVFxSrLPrZy5cqUlZXl5ptvzo477pgDDjggY8eOzfjx46s9qjN69OgsWrSo8jZ37tx1GRMAANhI1eiITtu2bVO/fv1Vjt7MmzdvlaM8H+vUqVO22GKLtG7dunJZ7969U1FRkTfeeCO9evVa5TmNGzdO48aNazIaAABApRod0WnUqFH69euXiRMnVlk+ceLE7LTTTqt9zs4775y33nor7733XuWyV199NfXq1cuWW265DiMDAACsWY1PXRs5cmSuu+663HDDDZk+fXpOPvnkzJkzJ0OHDk3y0WlngwYNqlz/sMMOS5s2bXL00Udn2rRpefTRR3PqqafmmGOOSdOmTdffKwEAAPj/anx56UMOOSQLFizIeeedl/Ly8vTp0yf33ntvunbtmiQpLy/PnDlzKtdv0aJFJk6cmBNPPDH9+/dPmzZt8p3vfCc/+clP1t+rAAAA+Bc1Dp0kGTZsWIYNG7bax8aPH7/Kss997nOrnO4GAABQW9bpqmsAAAAbMqEDAAAUjtABAAAKR+gAAACFI3QAAIDCEToAAEDhCB0AAKBwhA4AAFA4QgcAACgcoQMAABSO0AEAAApH6AAAAIUjdAAAgMIROgAAQOEIHQAAoHCEDgAAUDhCBwAAKByhAwAAFI7QAQAACkfoAAAAhSN0AACAwhE6AABA4QgdAACgcIQOAABQOEIHAAAoHKEDAAAUjtABAAAKR+gAAACFI3QAAIDCEToAAEDhCB0AAKBwhA4AAFA4QgcAACgcoQMAABSO0AEAAApH6AAAAIUjdAAAgMIROgAAQOEIHQAAoHCEDgAAUDhCBwAAKByhAwAAFI7QAQAACkfoAAAAhSN0AACAwhE6AABA4QgdAACgcIQOAABQOEIHAAAoHKEDAAAUjtABAAAKR+gAAACFI3QAAIDCEToAAEDhCB0AAKBwhA4AAFA4QgcAACgcoQMAABSO0AEAAApH6AAAAIUjdAAAgMIROgAAQOEIHQAAoHCEDgAAUDhCBwAAKByhAwAAFI7QAQAACkfoAAAAhSN0AACAwhE6AABA4QgdAACgcIQOAABQOEIHAAAoHKEDAAAUjtABAAAKR+gAAACFI3QAAIDCEToAAEDhCB0AAKBwhA4AAFA4QgcAACgcoQMAABSO0AEAAApH6AAAAIUjdAAAgMIROgAAQOEIHQAAoHCEDgAAUDhCBwAAKByhAwAAFI7QAQAACkfoAAAAhSN0AACAwhE6AABA4QgdAACgcIQOAABQOEIHAAAoHKEDAAAUjtABAAAKR+gAAACFI3QAAIDCEToAAEDhCB0AAKBwhA4AAFA4QgcAACgcoQMAABSO0AEAAApH6AAAAIUjdAAAgMIROgAAQOEIHQAAoHCEDgAAUDhCBwAAKByhAwAAFI7QAQAACkfoAAAAhSN0AACAwhE6AABA4QgdAACgcIQOAABQOEIHAAAoHKEDAAAUjtABAAAKZ51C54orrkj37t3TpEmT9OvXL4899thaPW/SpElp0KBBtttuu3XZLQAAwFqpcejcfvvtOemkk/KjH/0oU6ZMya677pr9998/c+bMWePzFi1alEGDBmXvvfde52EBAADWRo1DZ+zYsRk8eHCGDBmS3r1759JLL03nzp1z5ZVXrvF5xx13XA477LAMGDBgnYcFAABYGzUKnaVLl2by5MkZOHBgleUDBw7ME088Ue3zbrzxxsyYMSNnn332Wu1nyZIlWbx4cZUbAADA2qpR6MyfPz8rVqxIhw4dqizv0KFD3n777dU+57XXXssZZ5yRm2++OQ0aNFir/YwZMyatW7euvHXu3LkmYwIAABu5dboYQVlZWZX7FRUVqyxLkhUrVuSwww7Lueeem6233nqttz969OgsWrSo8jZ37tx1GRMAANhIrd0hlv+vbdu2qV+//ipHb+bNm7fKUZ4keffdd/Pss89mypQpOeGEE5IkK1euTEVFRRo0aJD7778/e+211yrPa9y4cRo3blyT0QAAACrV6IhOo0aN0q9fv0ycOLHK8okTJ2annXZaZf1WrVrlpZdeyvPPP195Gzp0aLbZZps8//zz+dKXvvTppgcAAFiNGh3RSZKRI0fmiCOOSP/+/TNgwIBcc801mTNnToYOHZrko9PO3nzzzfzyl79MvXr10qdPnyrPb9++fZo0abLKcgAAgPWlxqFzyCGHZMGCBTnvvPNSXl6ePn365N57703Xrl2TJOXl5Z/4nToAAAC1qcahkyTDhg3LsGHDVvvY+PHj1/jcc845J+ecc8667BYAAGCtrNNV1wAAADZkQgcAACgcoQMAABSO0AEAAApH6AAAAIUjdAAAgMIROgAAQOEIHQAAoHCEDgAAUDhCBwAAKByhAwAAFI7QAQAACkfoAAAAhSN0AACAwhE6AABA4QgdAACgcIQOAABQOEIHAAAoHKEDAAAUjtABAAAKR+gAAACFI3QAAIDCEToAAEDhCB0AAKBwhA4AAFA4QgcAACgcoQMAABSO0AEAAApH6AAAAIUjdAAAgMIROgAAQOEIHQAAoHCEDgAAUDhCBwAAKByhAwAAFI7QAQAACkfoAAAAhSN0AACAwhE6AABA4QgdAACgcIQOAABQOEIHAAAoHKEDAAAUjtABAAAKR+gAAACFI3QAAIDCEToAAEDhCB0AAKBwhA4AAFA4QgcAACgcoQMAABSO0AEAAApH6AAAAIUjdAAAgMIROgAAQOEIHQAAoHCEDgAAUDhCBwAAKByhAwAAFI7QAQAACkfoAAAAhSN0AACAwhE6AABA4QgdAACgcIQOAABQOEIHAAAoHKEDAAAUjtABAAAKR+gAAACFI3QAAIDCEToAAEDhCB0AAKBwhA4AAFA4QgcAACgcoQMAABSO0AEAAApH6AAAAIUjdAAAgMIROgAAQOEIHQAAoHCEDgAAUDhCBwAAKByhAwAAFI7QAQAACkfoAAAAhSN0AACAwhE6AABA4QgdAACgcIQOAABQOEIHAAAoHKEDAAAUjtABAAAKR+gAAACFI3QAAIDCEToAAEDhCB0AAKBwhA4AAFA4QgcAACgcoQMAABSO0AEAAApH6AAAAIUjdAAAgMIROgAAQOEIHQAAoHCEDgAAUDhCBwAAKByhAwAAFI7QAQAACkfoAAAAhSN0AACAwhE6AABA4QgdAACgcIQOAABQOEIHAAAoHKEDAAAUjtABAAAKR+gAAACFI3QAAIDCEToAAEDhCB0AAKBwhA4AAFA4QgcAACicdQqdK664It27d0+TJk3Sr1+/PPbYY9Wue9ddd2WfffZJu3bt0qpVqwwYMCATJkxY54EBAAA+SY1D5/bbb89JJ52UH/3oR5kyZUp23XXX7L///pkzZ85q13/00Uezzz775N57783kyZOz55575mtf+1qmTJnyqYcHAABYnRqHztixYzN48OAMGTIkvXv3zqWXXprOnTvnyiuvXO36l156aU477bT8x3/8R3r16pULLrggvXr1yu9///tPPTwAAMDq1Ch0li5dmsmTJ2fgwIFVlg8cODBPPPHEWm1j5cqVeffdd7PZZptVu86SJUuyePHiKjcAAIC1VaPQmT9/flasWJEOHTpUWd6hQ4e8/fbba7WNSy65JO+//36+853vVLvOmDFj0rp168pb586dazImAACwkVunixGUlZVVuV9RUbHKstW59dZbc8455+T2229P+/btq11v9OjRWbRoUeVt7ty56zImAACwkWpQk5Xbtm2b+vXrr3L0Zt68easc5fl3t99+ewYPHpw77rgjX/nKV9a4buPGjdO4ceOajAYAAFCpRkd0GjVqlH79+mXixIlVlk+cODE77bRTtc+79dZbc9RRR+WWW27JgQceuG6TAgAArKUaHdFJkpEjR+aII45I//79M2DAgFxzzTWZM2dOhg4dmuSj087efPPN/PKXv0zyUeQMGjQoP//5z/PlL3+58mhQ06ZN07p16/X4UgAAAD5S49A55JBDsmDBgpx33nkpLy9Pnz59cu+996Zr165JkvLy8irfqXP11Vdn+fLlGT58eIYPH165/Mgjj8z48eM//SsAAAD4NzUOnSQZNmxYhg0bttrH/j1eHn744XXZBQAAwDpbp6uuAQAAbMiEDgAAUDhCBwAAKByhAwAAFI7QAQAACkfoAAAAhSN0AACAwhE6AABA4QgdAACgcIQOAABQOEIHAAAoHKEDAAAUjtABAAAKR+gAAACFI3QAAIDCEToAAEDhCB0AAKBwhA4AAFA4QgcAACgcoQMAABSO0AEAAApH6AAAAIUjdAAAgMIROgAAQOEIHQAAoHCEDgAAUDhCBwAAKByhAwAAFI7QAQAACkfoAAAAhSN0AACAwhE6AABA4QgdAACgcIQOAABQOEIHAAAoHKEDAAAUjtABAAAKR+gAAACFI3QAAIDCEToAAEDhCB0AAKBwhA4AAFA4QgcAACgcoQMAABSO0AEAAApH6AAAAIUjdAAAgMIROgAAQOEIHQAAoHCEDgAAUDhCBwAAKByhAwAAFI7QAQAACkfoAAAAhSN0AACAwhE6AABA4QgdAACgcIQOAABQOEIHAAAoHKEDAAAUjtABAAAKR+gAAACFI3QAAIDCEToAAEDhCB0AAKBwhA4AAFA4QgcAACgcoQMAABSO0AEAAApH6AAAAIUjdAAAgMIROgAAQOEIHQAAoHCEDgAAUDhCBwAAKByhAwAAFI7QAQAACkfoAAAAhSN0AACAwhE6AABA4QgdAACgcIQOAABQOEIHAAAoHKEDAAAUjtABAAAKR+gAAACFI3QAAIDCEToAAEDhCB0AAKBwhA4AAFA4QgcAACgcoQMAABSO0AEAAApH6AAAAIUjdAAAgMIROgAAQOEIHQAAoHCEDgAAUDhCBwAAKByhAwAAFI7QAQAACkfoAAAAhSN0AACAwhE6AABA4QgdAACgcIQOAABQOEIHAAAoHKEDAAAUjtABAAAKR+gAAACFI3QAAIDCEToAAEDhCB0AAKBwhA4AAFA4QgcAACgcoQMAABSO0AEAAApH6AAAAIUjdAAAgMIROgAAQOEIHQAAoHCEDgAAUDhCBwAAKJx1Cp0rrrgi3bt3T5MmTdKvX7889thja1z/kUceSb9+/dKkSZP06NEjV1111ToNCwAAsDZqHDq33357TjrppPzoRz/KlClTsuuuu2b//ffPnDlzVrv+rFmzcsABB2TXXXfNlClT8sMf/jAjRozIb3/72089PAAAwOo0qOkTxo4dm8GDB2fIkCFJkksvvTQTJkzIlVdemTFjxqyy/lVXXZUuXbrk0ksvTZL07t07zz77bC6++OJ8+9vfXu0+lixZkiVLllTeX7RoUZJk8eLFNR13g7FyyQe1vo/FZRW1uv0V/1xRq9t/b0Xtbv+z/OenKGr7ffBZfw8k3gcbA++DNavt90DifbAh8D5YMz8L1uzj+SsqPuG/c0UNLFmypKJ+/foVd911V5XlI0aMqNhtt91W+5xdd921YsSIEVWW3XXXXRUNGjSoWLp06Wqfc/bZZ1ckcXNzc3Nzc3Nzc3NzW+1t7ty5a2yXGh3RmT9/flasWJEOHTpUWd6hQ4e8/fbbq33O22+/vdr1ly9fnvnz56dTp06rPGf06NEZOXJk5f2VK1dm4cKFadOmTcrKymoyMuvJ4sWL07lz58ydOzetWrUq9ThQ57wHwPsAEu+DDUFFRUXefffdbL755mtcr8anriVZJTYqKirWGCCrW391yz/WuHHjNG7cuMqyTTbZZB0mZX1r1aqVNzUbNe8B8D6AxPug1Fq3bv2J69ToYgRt27ZN/fr1Vzl6M2/evFWO2nysY8eOq12/QYMGadOmTU12DwAAsFZqFDqNGjVKv379MnHixCrLJ06cmJ122mm1zxkwYMAq699///3p379/GjZsWMNxAQAAPlmNLy89cuTIXHfddbnhhhsyffr0nHzyyZkzZ06GDh2a5KPP1wwaNKhy/aFDh+b111/PyJEjM3369Nxwww25/vrrc8opp6y/V0Gta9y4cc4+++xVTimEjYX3AHgfQOJ98FlSVlHxSddlW9UVV1yRn/70pykvL0+fPn0ybty47LbbbkmSo446KrNnz87DDz9cuf4jjzySk08+OVOnTs3mm2+e008/vTKMAAAA1rd1Ch0AAIANWY1PXQMAANjQCR0AAKBwhA4AAFA4QgcAACgcoQMAABSO0KFa/3qJcAAA+CxxeWmq1aRJk2yxxRY5+uijc+SRR6Zz586lHglK4tVXX83DDz+cefPmZeXKlVUeO+uss0o0FQClNHfu3Jx99tm54YYbSj0K1RA6VGvhwoX59a9/nfHjx+fFF1/M3nvvncGDB+cb3/hGGjVqVOrxoE5ce+21Of7449O2bdt07NgxZWVllY+VlZXlueeeK+F0UDu+9a1vrfW6d911Vy1OAhuuF154ITvssENWrFhR6lGohtBhrTz//PO54YYbcuutt2blypU5/PDDM3jw4Hzxi18s9WhQq7p27Zphw4bl9NNPL/UoUGeOPvrotV73xhtvrMVJoHR+97vfrfHxmTNnZtSoUUJnAyZ0WGtvvfVWrrnmmlx44YVp0KBBPvzwwwwYMCBXXXVVvvCFL5R6PKgVrVq1yvPPP58ePXqUehQA6lC9evVSVlaWNf1VuaysTOhswFyMgDVatmxZ7rzzzhxwwAHp2rVrJkyYkMsvvzx/+9vfMmvWrHTu3DkHH3xwqceEWnPwwQfn/vvvL/UYANSxTp065be//W1Wrly52ptTlzd8DUo9ABuuE088MbfeemuS5Hvf+15++tOfpk+fPpWPN2/ePBdeeGG6detWogmh9vXs2TNnnnlmnnrqqfTt2zcNGzas8viIESNKNBnUnu23377K59HWxF/2KKp+/frlueeeyze+8Y3VPv5JR3soPaeuUa299947Q4YMybe//e1qLz6wfPnyTJo0KbvvvnsdTwd1o3v37tU+VlZWlpkzZ9bhNFA3zj333LVe9+yzz67FSaA0XnzxxSxatCjvv/9+9ttvv9Wu8/777+fZZ5/1d6ANmNABAIB/Ub9+/ZSXl6d9+/bp0aNHnnnmmbRp06bUY1FDPqNDtcaMGbPaa8PfcMMNueiii0owEZRWRUWF0xQANgKbbLJJZs2alSSZPXv2Kt+hxmeD0KFaV199dT73uc+tsvwLX/hCrrrqqhJMBKXxy1/+Mn379k3Tpk3TtGnTbLvttvnVr35V6rGgTqxYsSIXX3xxdtxxx3Ts2DGbbbZZlRsU0be//e3svvvu6d69e8rKytK/f//06NFjtTc2XC5GQLXefvvtdOrUaZXl7dq1S3l5eQkmgro3duzYnHnmmTnhhBOy8847p6KiIpMmTcrQoUMzf/78nHzyyaUeEWrVueeem+uuuy4jR47MmWeemR/96EeZPXt27rnnnpx11lmlHg9qxTXXXJNvfetb+etf/5oRI0bk2GOPTcuWLUs9FjXkMzpUq1evXjn77LPzve99r8ryX/3qVzn77LN9CJuNQvfu3XPuuedm0KBBVZbfdNNNOeeccypPbYCi2mqrrXLZZZflwAMPTMuWLfP8889XLnvqqadyyy23lHpEqFVHH310LrvsMqHzGeSIDtUaMmRITjrppCxbtix77bVXkuSBBx7IaaedllGjRpV4Oqgb5eXl2WmnnVZZvtNOOzmyyUbh7bffTt++fZMkLVq0yKJFi5IkX/3qV3PmmWeWcjSoEzfeeGOpR2AdCR2qddppp2XhwoUZNmxYli5dmiRp0qRJTj/99IwePbrE00Hd6NmzZ37zm9/khz/8YZXlt99+e3r16lWiqaDubLnllikvL0+XLl3Ss2fP3H///dlhhx3yzDPPpHHjxqUeD6BaTl3jE7333nuZPn16mjZtml69evnBxkblt7/9bQ455JB85Stfyc4775yysrI8/vjjeeCBB/Kb3/wm3/zmN0s9ItSqM844I61atcoPf/jD3HnnnTn00EPTrVu3zJkzJyeffHIuvPDCUo8IsFpCB+ATTJ48OePGjcv06dNTUVGRz3/+8xk1alS23377Uo8Gde7pp5/OpEmT0rNnzxx00EGlHgegWkKHNXrmmWdyxx13ZM6cOZWnr33srrvuKtFUAACwZr5Hh2rddttt2XnnnTNt2rTcfffdWbZsWaZNm5YHH3wwrVu3LvV4UGsWL15c5ddrukHR+fJo4LPKER2qte222+a4447L8OHD07Jly7zwwgvp3r17jjvuuHTq1CnnnntuqUeEWlG/fv2Ul5enffv2qVevXsrKylZZp6KiImVlZVmxYkUJJoS6061bt9xyyy2rXH3w6aefzne/+12XWAc2WK66RrVmzJiRAw88MEnSuHHjvP/++ykrK8vJJ5+cvfbaS+hQWA8++GDlN74/9NBDJZ4GSsuXRwOfVUKHam222WZ59913kyRbbLFFXn755fTt2zfvvPNOPvjggxJPB7Vn9913X+2vYWPUuXPnTJo0Kd27d6+yfNKkSdl8881LNBXAJ/MZHaq16667ZuLEiUmS73znO/nBD36QY489Noceemj23nvvEk8HdeO+++7L448/Xnn/v//7v7PddtvlsMMOyz/+8Y8STgZ14+Mvj77xxhvz+uuv5/XXX88NN9yQk08+Occee2ypxwOols/oUK2FCxfmww8/zOabb56VK1fm4osvzuOPP56ePXvmzDPPzKabblrqEaHW9e3bNxdddFEOOOCAvPTSS+nfv39GjRqVBx98ML179/aN2RReRUVFzjjjjFx22WWrfHn0WWedVeLpAKondFit5cuX5+abb86+++6bjh07lnocKJkWLVrk5ZdfTrdu3XLOOefk5Zdfzp133pnnnnsuBxxwQN5+++1Sjwh1wpdHA581Tl1jtRo0aJDjjz8+S5YsKfUoUFKNGjWq/Ezan/70pwwcODDJR59hc3lpNiZvv/12Fi5cmK222iqNGzeOfycFNnRCh2p96UtfypQpU0o9BpTULrvskpEjR+b888/Pn//858orEb766qvZcsstSzwd1L4FCxZk7733ztZbb50DDjig8kprQ4YMyahRo0o8HUD1hA7VGjZsWEaNGpXLL788Tz75ZF588cUqN9gYXH755WnQoEHuvPPOXHnlldliiy2SJH/84x+z3377lXg6qH0nn3xyGjZsmDlz5qRZs2aVyw855JDcd999JZwMYM18Rodq1au3ageXlZX5okSAjUjHjh0zYcKEfPGLX6z88ugePXpk1qxZ6du3b957771SjwiwWr5Hh2r5tms2VosXL06rVq0qf70mH68HRfX+++9XOZLzsfnz57sgAbBBc0QH4N/Ur18/5eXlad++ferVq5eysrJV1nFkk43FgQcemB122CHnn39+WrZsmRdffDFdu3bNd7/73axcuTJ33nlnqUcEWC1HdKjWL3/5yzU+PmjQoDqaBOrWgw8+mM022yxJ8tBDD5V4Giitiy++OLvvvnueffbZLF26NKeddlqmTp2ahQsXZtKkSaUeD6BajuhQrX//QtBly5blgw8+SKNGjdKsWbMsXLiwRJMBUBeWLVuWgQMHZsyYMfnjH/+YyZMnZ+XKldlhhx0yfPjwdOrUqdQjAlRL6FAjr732Wo4//viceuqp2XfffUs9DtS6G2+8MS1atMjBBx9cZfkdd9yRDz74IEceeWSJJoO60a5duzzxxBPp1atXqUcBqBGXl6ZGevXqlQsvvDA/+MEPSj0K1IkLL7wwbdu2XWV5+/btc8EFF5RgIqhbgwYNyvXXX1/qMQBqzGd0qLH69evnrbfeKvUYUCdef/31dO/efZXlXbt2zZw5c0owEdStpUuX5rrrrsvEiRPTv3//NG/evMrjY8eOLdFkAGsmdKjW7373uyr3KyoqUl5enssvvzw777xziaaCutW+ffu8+OKL6datW5XlL7zwQtq0aVOaoaAOvfzyy9lhhx2SJK+++mqVx1Z3RUKADYXQoVrf+MY3qtwvKytLu3btstdee+WSSy4pzVBQx7773e9mxIgRadmyZXbbbbckySOPPJIf/OAH+e53v1vi6aD2ufIg8FnlYgQAa7B06dIcccQRueOOO9KgwUf/NrRy5coMGjQoV111VRo1alTiCQGA1RE6AGvh1VdfzQsvvJCmTZumb9++6dq1a6lHAgDWwKlrVOs///M/079//5xxxhlVlv/sZz/Ln//859xxxx0lmgzqXrdu3VJRUZGtttqq8sgOALDhcnlpqvXII4/kwAMPXGX5fvvtl0cffbQEE0Hd++CDDzJ48OA0a9YsX/jCFyqvtDZixIhceOGFJZ4OAKiO0KFa77333mo/f9CwYcMsXry4BBNB3Rs9enReeOGFPPzww2nSpEnl8q985Su5/fbbSzgZALAmQodq9enTZ7V/kbvtttvy+c9/vgQTQd275557cvnll2eXXXapcindz3/+85kxY0YJJwMA1sSJ5lTrzDPPzLe//e3MmDEje+21V5LkgQceyK233urzOWw0/v73v6d9+/arLH///fd9hwgAbMAc0aFaBx10UO6555789a9/zbBhwzJq1Ki88cYb+dOf/rTKd+xAUf3Hf/xH/vCHP1Te/zhurr322gwYMKBUYwEAn8DlpQHW4Iknnsh+++2Xww8/POPHj89xxx2XqVOn5sknn8wjjzySfv36lXpEAGA1HNGhWs8880yefvrpVZY//fTTefbZZ0swEdS9nXbaKU888UQ++OCDbLXVVrn//vvToUOHPPnkkyIHADZgQodqDR8+PHPnzl1l+Ztvvpnhw4eXYCKoW8uWLcvRRx+dZs2a5aabbsrLL7+cadOm5de//nX69u1b6vEAgDUQOlRr2rRp2WGHHVZZvv3222fatGklmAjqVsOGDXP33XeXegwAYB0IHarVuHHj/O1vf1tleXl5uW+GZ6PxzW9+M/fcc0+pxwAAasjfVqnWPvvsk9GjR+d//ud/0rp16yTJO++8kx/+8IfZZ599Sjwd1I2ePXvm/PPPzxNPPJF+/fqlefPmVR4fMWJEiSYDANbEVdeo1ptvvpnddtstCxYsyPbbb58kef7559OhQ4dMnDgxnTt3LvGEUPu6d+9e7WNlZWWZOXNmHU4DAKwtocMavf/++7n55pvzwgsvpGnTptl2221z6KGHpmHDhqUeDercx/936YtCAWDDJ3T4RNOmTcucOXOydOnSKssPOuigEk0Edev666/PuHHj8tprryVJevXqlZNOOilDhgwp8WQAQHV8RodqzZw5M9/85jfz0ksvpaysLBUVFVX+JXvFihUlnA7qxplnnplx48blxBNPzIABA5IkTz75ZE4++eTMnj07P/nJT0o8IQCwOo7oUK2vfe1rqV+/fq699tr06NEjTz/9dBYuXJhRo0bl4osvzq677lrqEaHWtW3bNr/4xS9y6KGHVll+66235sQTT8z8+fNLNBkAsCaO6FCtJ598Mg8++GDatWuXevXqpX79+tlll10yZsyYjBgxIlOmTCn1iFDrVqxYkf79+6+yvF+/flm+fHkJJgIA1obv0aFaK1asSIsWLZJ89K/ab731VpKka9eu+ctf/lLK0aDOfO9738uVV165yvJrrrkmhx9+eAkmAgDWhiM6VKtPnz558cUX06NHj3zpS1/KT3/60zRq1CjXXHNNevToUerxoM5cf/31uf/++/PlL385SfLUU09l7ty5GTRoUEaOHFm53tixY0s1IgDwb3xGh2pNmDAh77//fr71rW9l5syZ+epXv5pXXnklbdq0ye2335699tqr1CNCrdtzzz3Xar2ysrI8+OCDtTwNALC2hA41snDhwmy66aa+RwQAgA2a0AEAAArHxQgAAIDCEToAAEDhCB0AAKBwhA4AAFA4QgcAACgcoQMAABSO0AEAAArn/wEMMLt7lCBgjAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare_metrics = pd.DataFrame({\"baseline\": baseline_metrics,\n",
    "                              \"clf_2\": clf_2_metrics,\n",
    "                              \"random search\": rs_metrics,\n",
    "                              \"grid search\": gs_metrics})\n",
    "\n",
    "compare_metrics.plot.bar(figsize=(10,8));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907ddf9c",
   "metadata": {},
   "source": [
    "## 6. Saving and loading trained machine learning models\n",
    "\n",
    "Two ways to save and load machine learning models:\n",
    "1. With Python's `pickle` module\n",
    "2. With the `joblib` module\n",
    "\n",
    "Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3b0d899c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "#Save an exisiting model to file\n",
    "\n",
    "pickle.dump(gs_clf, open(\"gs_random_random_forest_model_1.pk1\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7b90c092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a saved model\n",
    "loaded_pickle_model = pickle.load(open(\"gs_random_random_forest_model_1.pk1\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a937beeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 81.97%\n",
      "Precision: 0.77\n",
      "Recall: 0.86\n",
      "F1 score: 0.81\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.82, 'precision': 0.77, 'recall': 0.86, 'f1': 0.81}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make some predictions\n",
    "pickle_y_preds = loaded_pickle_model.predict(X_test)\n",
    "evaluate_preds(y_test, pickle_y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964d966a",
   "metadata": {},
   "source": [
    "**Joblib**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8046c43c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gs_random_forest_model_1.joblib']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "#Save model to file\n",
    "dump(gs_clf, filename=\"gs_random_forest_model_1.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a7416e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import a saved joblib model\n",
    "loaded_joblib_model = load(filename=\"gs_random_forest_model_1.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "81205979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 81.97%\n",
      "Precision: 0.77\n",
      "Recall: 0.86\n",
      "F1 score: 0.81\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.82, 'precision': 0.77, 'recall': 0.86, 'f1': 0.81}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make and evaluate joblib predictions\n",
    "joblib_y_preds = loaded_joblib_model.predict(X_test)\n",
    "evaluate_preds(y_test, joblib_y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23231b93",
   "metadata": {},
   "source": [
    "## 7. Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5d7ecac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Make</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Odometer (KM)</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>35431.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15323.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMW</td>\n",
       "      <td>Blue</td>\n",
       "      <td>192714.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19943.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>84714.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28343.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>White</td>\n",
       "      <td>154365.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13434.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>181577.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14043.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Black</td>\n",
       "      <td>35820.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32042.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>White</td>\n",
       "      <td>155144.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5716.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>66604.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>31570.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>215883.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Blue</td>\n",
       "      <td>248360.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12732.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Make Colour  Odometer (KM)  Doors    Price\n",
       "0     Honda  White        35431.0    4.0  15323.0\n",
       "1       BMW   Blue       192714.0    5.0  19943.0\n",
       "2     Honda  White        84714.0    4.0  28343.0\n",
       "3    Toyota  White       154365.0    4.0  13434.0\n",
       "4    Nissan   Blue       181577.0    3.0  14043.0\n",
       "..      ...    ...            ...    ...      ...\n",
       "995  Toyota  Black        35820.0    4.0  32042.0\n",
       "996     NaN  White       155144.0    3.0   5716.0\n",
       "997  Nissan   Blue        66604.0    4.0  31570.0\n",
       "998   Honda  White       215883.0    4.0   4001.0\n",
       "999  Toyota   Blue       248360.0    4.0  12732.0\n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"car-sales-extended-missing-data.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "204658e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make              object\n",
       "Colour            object\n",
       "Odometer (KM)    float64\n",
       "Doors            float64\n",
       "Price            float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2635d0a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             49\n",
       "Colour           50\n",
       "Odometer (KM)    50\n",
       "Doors            50\n",
       "Price            50\n",
       "dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2672699",
   "metadata": {},
   "source": [
    "Steps to do (all in one cell):\n",
    "1. Fill missing data\n",
    "2. Convert data to numbers\n",
    "3. Build a model on the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f47df5c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22188417408787875"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting data ready\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#Modeling\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "#Setup random seed\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "#Import data and drop rows with missing labels\n",
    "data = pd.read_csv(\"car-sales-extended-missing-data.csv\")\n",
    "data.dropna(subset=[\"Price\"], inplace=True)\n",
    "\n",
    "#Define different features and transformer pipeline\n",
    "categorical_features = [\"Make\", \"Colour\"]\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))])\n",
    "\n",
    "door_feature = [\"Doors\"]\n",
    "door_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=4))\n",
    "])\n",
    "\n",
    "numeric_features = [\"Odometer (KM)\"]\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\"))\n",
    "])\n",
    "\n",
    "#Setup preprocessing steps (fill missing values, then convert to numbers)\n",
    "preprocessor = ColumnTransformer(\n",
    "                transformers=[\n",
    "                    (\"cat\", categorical_transformer, categorical_features),\n",
    "                    (\"door\", door_transformer, door_feature),\n",
    "                    (\"num\", numeric_transformer, numeric_features)\n",
    "                ])\n",
    "#Creating a preprocessing and modeling pipeline\n",
    "model = Pipeline(steps=[(\"preprocessor\", preprocessor),\n",
    "                       (\"model\", RandomForestRegressor())])\n",
    "\n",
    "#Split data\n",
    "X = data.drop(\"Price\", axis=1)\n",
    "y= data[\"Price\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "#Fit and score the model\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edf144d",
   "metadata": {},
   "source": [
    "It's also possible to use `GridSearchCV` or `RandomizedSearchCV` with our `Pipeline`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "600edf97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.0s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.0s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.0s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.0s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.0s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.0s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.0s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.0s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.0s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.0s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   0.0s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   0.0s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   0.0s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   0.0s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   0.0s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   0.0s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   0.0s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   0.0s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   0.0s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   0.0s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.0s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.0s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.0s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.0s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.0s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.0s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.0s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.0s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.0s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.0s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   0.0s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   0.0s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   0.0s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   0.0s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   0.0s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   0.0s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   0.0s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   0.0s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   0.0s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   0.0s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.0s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.0s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.0s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.0s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.0s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.0s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.0s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.0s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.0s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.0s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   0.0s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   0.0s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   0.0s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   0.0s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   0.0s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   0.0s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   0.0s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   0.0s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   0.0s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.0s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.0s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.0s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.0s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.0s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.0s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.0s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.0s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.0s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.0s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   0.0s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   0.0s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   0.0s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   0.0s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   0.0s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   0.0s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   0.0s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   0.0s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   0.0s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   0.0s\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 80 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n80 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Users/hameed/Desktop/WebDevelopment/sample_project/env/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/hameed/Desktop/WebDevelopment/sample_project/env/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/hameed/Desktop/WebDevelopment/sample_project/env/lib/python3.10/site-packages/sklearn/pipeline.py\", line 420, in fit\n    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n  File \"/Users/hameed/Desktop/WebDevelopment/sample_project/env/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/hameed/Desktop/WebDevelopment/sample_project/env/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/hameed/Desktop/WebDevelopment/sample_project/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[84], line 13\u001b[0m\n\u001b[1;32m      4\u001b[0m pipe_grid \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpreprocessor__num__imputer__strategy\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedian\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel__n_estimators\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m1000\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel__min_samples_split\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m4\u001b[39m]\n\u001b[1;32m     10\u001b[0m }\n\u001b[1;32m     12\u001b[0m gs_model \u001b[38;5;241m=\u001b[39m GridSearchCV(model, pipe_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m \u001b[43mgs_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/WebDevelopment/sample_project/env/lib/python3.10/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/WebDevelopment/sample_project/env/lib/python3.10/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Desktop/WebDevelopment/sample_project/env/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1419\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1418\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1419\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/WebDevelopment/sample_project/env/lib/python3.10/site-packages/sklearn/model_selection/_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    870\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[1;32m    873\u001b[0m     )\n\u001b[0;32m--> 875\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[0;32m~/Desktop/WebDevelopment/sample_project/env/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:414\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[1;32m    408\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    409\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    410\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    411\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    412\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    413\u001b[0m     )\n\u001b[0;32m--> 414\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    418\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    419\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    424\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 80 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n80 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Users/hameed/Desktop/WebDevelopment/sample_project/env/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/hameed/Desktop/WebDevelopment/sample_project/env/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/hameed/Desktop/WebDevelopment/sample_project/env/lib/python3.10/site-packages/sklearn/pipeline.py\", line 420, in fit\n    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n  File \"/Users/hameed/Desktop/WebDevelopment/sample_project/env/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"/Users/hameed/Desktop/WebDevelopment/sample_project/env/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"/Users/hameed/Desktop/WebDevelopment/sample_project/env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n"
     ]
    }
   ],
   "source": [
    "# Use GridSearchCV with our regression Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pipe_grid = {\n",
    "    \"preprocessor__num__imputer__strategy\": [\"mean\", \"median\"],\n",
    "    \"model__n_estimators\": [100, 1000],\n",
    "    \"model__max_depth\": [None, 5],\n",
    "    \"model__max_features\": [\"auto\"],\n",
    "    \"model__min_samples_split\": [2, 4]\n",
    "}\n",
    "\n",
    "gs_model = GridSearchCV(model, pipe_grid, cv=5, verbose=2)\n",
    "gs_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "18e7c2a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This GridSearchCV instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[82], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgs_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/WebDevelopment/sample_project/env/lib/python3.10/site-packages/sklearn/model_selection/_search.py:456\u001b[0m, in \u001b[0;36mBaseSearchCV.score\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the score on the given data, if the estimator has been refit.\u001b[39;00m\n\u001b[1;32m    434\u001b[0m \n\u001b[1;32m    435\u001b[0m \u001b[38;5;124;03mThis uses the score defined by ``scoring`` where provided, and the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;124;03m    ``best_estimator_.score`` method otherwise.\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    455\u001b[0m _check_refit(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 456\u001b[0m \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscorer_ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    459\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo score function explicitly defined, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    460\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand the estimator doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt provide one \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    461\u001b[0m         \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[1;32m    462\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/WebDevelopment/sample_project/env/lib/python3.10/site-packages/sklearn/utils/validation.py:1462\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1459\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not an estimator instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (estimator))\n\u001b[1;32m   1461\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001b[0;32m-> 1462\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This GridSearchCV instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "gs_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa22404",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
